{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to BrainSight","text":""},{"location":"#what-is-it","title":"What is it?","text":"<p>BrainSight is a python-based toolkit that simplifies the analysis of Kelvin-created multimodal datasets containing kinematic and brain-sensing data captured during a motor assessment.</p> <p>These modalities include, among others:</p> <ul> <li>Local field potential (LFP) signals,</li> <li>Pose estimation data,</li> <li>Automatically detected activity regions.</li> </ul> <p>Full description of the dataset creation can be found here.</p>"},{"location":"#try-it-out","title":"Try it out","text":"<p>Find out how to <code>install</code> this cool package.</p> <p>Then learn how to use it by checking out the <code>demo</code> notebook.</p> <p>For more details see the <code>docs</code></p>"},{"location":"#who-do-i-talk-to","title":"Who do I talk to?","text":"<p>For news and issues check out our <code>GitHub</code> page!</p> <p>If you have any questions about the package, reach out to us at:</p> <p>MMT Analytics | analytics@machinemedicine.com</p>"},{"location":"documentation/","title":"Using BrainSight","text":"<p>These pages serve as an overview of BrainSight and concepts related to the package.</p> <ul> <li>Multimodal dataset</li> <li>LFP Synchronisation</li> </ul>"},{"location":"documentation/#tutorials","title":"Tutorials","text":"<p>Tutorials contain explanations, sample code, and expected output for selected analysis tasks that could be performed using BrainSight.</p> <ul> <li>Beta band analysis</li> </ul>"},{"location":"documentation/dataset/","title":"Multimodal Dataset Creation","text":"<p>The true potential of BrainSight is realized when analyzing data within multimodal datasets created exclusively by the Kelvin platform.</p> <p>Users who capture MDS-UPDRS Part III assessments using the Kelvin Clinic\u2122 application can attach to them the JSON session report exported from Medtronic's Percept PC/RC neurostimulator and benefit from the automatic processing and synchronization of LFP signals with rich kinematic video data.</p> <p>NOTE: In order for the automatic synchronisation to work properly, the assessment needs to be captured following the LFP synchronisation procedure.</p> <p>Dataset creation begins when the Percept report is uploaded by the user. Once processed, it is available for download in JSON format. This file can then be easily read and explored using the Dataset class.</p>"},{"location":"documentation/dataset/#modalities","title":"Modalities","text":"<p>Here is a list of all modalities contained within the dataset:</p> Modality Description LFP Local field potential signals extracted from the Percept JSON session report POSE X- and Y-coordinate signals for 75 automatically detected body key-points ACTIVITY Regions of assessment-specific activities recognized within the videos MDS_UPDRS List of user-provided MDS-UPDRS Part III ratings ACCELEROMETER Acceleration signal recorded by the assessment-capture device ASSESSMENT_INFO Reference, date, and user email attached to the Kelvin assessment VIDEO_METADATA Metadata extracted from the assessment items' video files <p>When successfully processed, all modalities ought to be synchronised in time, enabling the simultaneous analysis of the brain and motor activity! </p> <p>Find out how to perform simple analysis by viewing our Tutorials page.</p>"},{"location":"documentation/synchronisation/","title":"Synchronising LFP and Video Data","text":"<p>Several deep brain stimulation (DBS) systems now allow for simultaneous stimulation and local field potential (LFP) recording. While conventional DBS is an effective therapy for neurological disorders like Parkinson's disease (PD), synchronizing neuronal activity signals with behavioural measures could reveal mechanisms underlying motor control in health and disease. To achieve this, we define a method for synchronizing LFP signals from a stimulation device with external visual data with sub-second precision.</p>"},{"location":"documentation/synchronisation/#method","title":"Method","text":"<p>To automatically synchronise LFP data with video one needs the Percept\u2122 PC, a neurostimulation device implanted in PD patients capable of measuring LFP signals; a video-enabled smart device, such as a consumer-grade smartphone or tablet running iOS or Android; and the the Kelvin Clinic\u2122 App, available in iOS and Android app stores, which allows for video recording of the MDS-UPDRS motor assessment and export of the device's accelerometer data.</p> <p>The data capture procedure involves the following steps:</p> <ol> <li>Updating the DBS device's internal clock through the tablet controller, synchronizing the stimulator's clock with the control tablet.</li> <li>Starting the video assessment on the App and beginning the LFP capture session.</li> <li>While recording, tapping four times on the patient's implanted pulse generator with the smart device to induce artefacts in the LFP signal. The tapping pattern is aperiodic, created by counting slowly (approximately 1Hz) and steadily to 8, tapping on the 1st, 2nd, 4th, and 8th beats.</li> <li>Recording the rest of the motor assessment, stabilizing the camera device (e.g., using a tripod) and ensuring the patient is entirely in the shot.</li> </ol> <p>The first step achieves coarse synchronization in the order of seconds. Sub-second synchronization of the LFP and video data is obtained by aligning the induced LFP artefacts with acceleration spikes from the smart device's built-in accelerometer. Since the accelerometer and the camera share the smart device's internal clock, aligning video frames with the DBS signal follows naturally.</p>"},{"location":"documentation/tutorials/","title":"Using BrainSight","text":"<p>With a series of tutorials we demonstrate how the data management and processing functionality of Kelvin can be leveraged by BrainSight to produce robust analysis of the local field potentials data at scale.</p> <p>Using real code examples we will explore the key functionality of BrainSight:</p> <ol> <li>Signal Preprocessing: Functions to filter and clean LFP signals, ensuring high-quality data for analysis.</li> <li>Frequency Analysis: Tools to extract and analyze beta band oscillations, allowing detailed examination of neural activity patterns.</li> <li>Region Comparison: Methods to compare LFP characteristics within motor regions versus non-motor regions, highlighting functional differences.</li> <li>Visualization: Comprehensive plotting utilities to visualize LFP signals, power spectra, and spatial distribution of neural activity.</li> </ol>"},{"location":"documentation/tutorials/#introduction","title":"Introduction","text":"<p>For a brief introduction to the basic functionality of BrainSight please visit the <code>demo</code> page.</p>"},{"location":"documentation/tutorials/#sample-analysis","title":"Sample analysis","text":"<p>Here, we demonstrate example workflows:</p> <ul> <li>Beta band analysis</li> </ul>"},{"location":"documentation/tutorials/beta/","title":"Introduction to Analysing Brain LFP Signals in the Beta Frequency Band","text":"<p>Understanding the brain's electrical activity is crucial for advancing both neuroscience research and clinical applications. Local Field Potentials (LFPs) offer a unique window into brain dynamics, providing insights into neural oscillations and their role in various cognitive and motor functions. Particularly, the beta frequency band (13-30 Hz) has been extensively studied due to its association with motor control and neurological disorders such as Parkinson's disease.</p> <p>This tutorial showcases how BrainSight can be used to analyse LFP signals in the beta frequency band, focusing on data collected from both within and outside a patient's motor activity regions. Whether you are a neuroscientist, a clinical researcher, or a data scientist interested in neural data analysis, BrainSight offers powerful tools to explore and interpret LFP data.</p>"},{"location":"documentation/tutorials/beta/#prerequisites","title":"Prerequisites","text":"<p>To make the most out of this tutorial, you should have:</p> <ul> <li>Basic knowledge of Python programming.</li> <li>Familiarity with signal processing concepts.</li> <li>An understanding of neural electrophysiology and the significance of the beta frequency band.</li> </ul> <p>In the following sections, we will guide you through the installation process, demonstrate how to read and process the multimodal datasets downloaded from the Kelvin platform and provide examples of visualizing and interpreting your results.</p> <p>NOTE: To start using BrainSight for analyzing brain LFP signals in the beta frequency band, you'll need to install it following our installation guide.</p>"},{"location":"documentation/tutorials/beta/#reading-the-data","title":"Reading the Data","text":"<p>In this tutorial we perform the analysis using multimodal dataset files containing both LFP signals captured during standard MDS-UPDRS part III motor assessments and corresponding patient activity regions. To learn how these datasets are created please refer to the multimodal dataset creation page.</p> <p>Once dataset JSON files have been downloaded into a local directory we can load them one-by-one into our environment.</p> <pre><code>datasets = {}\n# Iterate over the dataset JSON files\nfor path in glob.glob(\"../data/datasets/*.json\"):\n    # Create a Dataset instance\n    dataset = brain.Dataset(path)\n    # Check if the dataset is synchronised\n    if dataset.ASSESSMENT_INFO.SUB_SECOND_SYNCHRONISATION:\n        # Use the assessment's reference as a key\n        datasets[dataset.ASSESSMENT_INFO.REFERENCE] = dataset\n</code></pre> <p>We have used each assessment's reference to organise the datasets. Since we are interested in relating patients' activity regions to LFP signals we filter the datasets to those that have been successfully synchronised by the dataset creation pipeline. </p> <p>NOTE: To learn how we achieve the LFP-video synchronisation check out the LFP synchronisation page!</p> <p>We can verify if the synchronisation has worked as expected by plotting the raw LFP signal together with assessment device's accelerometer reading.</p> <pre><code>#\u00a0Select one of the datasets\nsample_reference = \"Assessment1\"\n\n# Create an instance of the LFP module\nlfp = brain.LFP(datasets[sample_reference])\n\n# Draw raw LFP signals including the accelerometer reading\nfig = lfp.plot(roi=(\"00:01:24\", \"00:01:38\"), show_accelerometer=True)\n</code></pre> <p>Output: </p> <p>As we can see, artefacts induced in the <code>ZERO_TWO_RIGHT</code> channel have been aligned with the accelerometer signal captured by the assessment-recording device. To ensure robustness of the analysis it may be a good idea to verify synchronisation for all datasets.</p>"},{"location":"documentation/tutorials/beta/#extracting-beta-power","title":"Extracting Beta Power","text":"<p>Now that we have read and verified our datasets, we can get right into the analysis. First, we define some helper functions to extract the information of interest from our samples. Using BrainSight's <code>Periodogram</code> module we can compute the power spectral density (PSD) for the detected activity regions across all LFP channels contained within a dataset. </p> <pre><code>import numpy as np\nfrom collections import defaultdict\n\ndef get_band_sum(\n    power: np.ndarray, freqs: np.ndarray, band: tuple[int, int]\n) -&gt; float:\n    \"\"\"Sum `power` corresponding to frequencies found within the specified `band`\"\"\"\n    start, stop = band\n    (overlap,) = np.where((start &lt;= freqs) &amp; (freqs &lt; stop))\n    return np.sum(power[overlap])\n\n\ndef get_activity_band_sums(\n    dataset: brain.Dataset, band: tuple[int, int]\n) -&gt; dict:\n    \"\"\"Compute the PSD for all channel-activity pairs found in the `dataset`\"\"\"\n\n    psd = brain.Periodogram(dataset)\n\n    sums = defaultdict(dict)\n    # Iterate over LFP sensing channels\n    for channel in dataset.LFP.keys():\n\n        # Iterate over all detected activities\n        for activity in dataset.ACTIVITY.keys():\n\n            # Compute the PSD for the activity region\n            power, freqs = psd.get_data(channel=channel, roi=activity)\n            s = get_band_sum(power, freqs, band)\n\n            sums[(\"activity\", activity)][channel] = s\n\n    return dict(sums)\n\ndef get_inactivity_band_sums(dataset: brain.Dataset, band: tuple[int, int]):\n    \"\"\"Compute the mean PSD for all 'inactivity' regions within the `dataset`\"\"\"\n\n    psd = brain.Periodogram(dataset)\n\n    # Get activity ROI ends\n    roi_ends = sorted(sum(dataset.ACTIVITY.values(), []))[1:-1]\n\n    # Find the average inactivity power for all channels\n    channel_sums = defaultdict(list)\n    for channel in dataset.LFP.keys():\n\n        # Iterate over compliments of the activity regions\n        for start, stop in zip(roi_ends[::2], roi_ends[1::2]):\n\n            power, freqs = psd.get_data(channel, (start, stop))\n            s = get_band_sum(power, freqs, band)\n\n            channel_sums[channel].append(s)\n\n        channel_sums[channel] = sum(channel_sums[channel]) / len(\n            channel_sums[channel]\n        )\n\n    return channel_sums\n</code></pre> <p>The <code>get_band_sum</code> function sums power estimates for frequencies within the specified interval. In our case, we will be interested in the frequency range of 13-30Hz. <code>get_activity_band_sums</code> iterates over all LFP channels and activities contained within a dataset computing the power sums. To compute the baseline beta power, ie. within inactivity regions, we assume that motor inactivity occurs inbetween the detected activity regions. Hence, <code>get_inactivity_band_sums</code> function finds the compliment of detected activity regions and computes their average beta power.</p> <p>Putting all functions together we can now process all our samples:</p> <pre><code>import pandas as pd\n\nbeta_band = (13.0, 30.0)  # Frequency band we are interested in\n\ndata = list()\nfor dataset in datasets.values():\n    # Compute power in activity and inactivity regions\n    power_dict = get_activity_band_sums(dataset=dataset, band=beta_band)\n    power_dict[(\"BASELINE\")] = get_inactivity_band_sums(\n        dataset=dataset, band=beta_band\n    )\n\n    # Construct a dataframe entry with additional assessment information\n    df = (\n        pd.DataFrame(power_dict)\n        .assign(**dataset.ASSESSMENT_INFO)\n        .reset_index(names=[\"CHANNEL\"])\n        .set_index(\n            [\n                \"SUBJECT_ID\",\n                \"REFERENCE\",\n                \"CHANNEL\",\n                \"MEDICATION_ON\",\n                \"STIMULATION_ON\",\n            ]\n        )\n        .drop(\"SUB_SECOND_SYNCHRONISATION\", axis=1)\n    )\n    data.append(df)\n\n# Concatenate all samples into one dataframe\ndataframe = pd.concat(data)\n</code></pre> <p>And that's it! We have successfully created a dataframe containing beta power estimates for every activity performed by all of our patients. Since our multimodal datasets contain information on the medication and stimulation states, performing more advanced comparisons is right within our reach. Here we see a snippet of the dataframe:</p> SUBJECT_ID REFERENCE CHANNEL MEDICATION_ON STIMULATION_ON TOE_TAPPING_LEFT GAIT_TOWARDS_CAMERA POSTURAL_TREMOR_OF_HANDS_LEFT GAIT_FROM_CAMERA LEG_AGILITY_RIGHT ARISING_FROM_CHAIR HAND_MOVEMENTS_RIGHT TOE_TAPPING_RIGHT HAND_MOVEMENTS_LEFT FINGER_TAPPING_LEFT LEG_AGILITY_LEFT FINGER_TAPPING_RIGHT BASELINE 4 assessment_0 ZERO_TWO_LEFT False False 1206.13 3114.78 1374.42 2803.22 2915.43 1032.72 2026.53 2524.83 2750.41 2017.21 5610.23 2174.24 10918.1 4 assessment_0 ZERO_TWO_RIGHT False False 1340.77 7700.09 2508.54 6730.55 18382.9 2122.44 6112.77 6102.84 7618.44 5905.21 4968.51 5016.53 25376.8 2 assessment_1 ZERO_TWO_LEFT True True 27138.8 42735.3 35339.6 52508.9 35950.5 7582.67 26288.8 17765.2 3553.74 nan 26559.6 nan 141750 2 assessment_1 ZERO_TWO_RIGHT True True 10559.1 16654.8 15932 17972.3 12780.5 3222.44 15441.8 7030.82 1655.62 nan 9399.49 nan 55659.1 4 assessment_2 ZERO_TWO_LEFT False True 2002.84 3061.84 1832.17 3515.71 1645.21 526.639 1398.32 2587.47 1805.58 1042.19 3480.59 1286.9 9709 4 assessment_2 ZERO_TWO_RIGHT False True 2343.3 6177.3 1945.4 6711.53 10332.2 1002.4 1540.19 2826.41 3387.87 1549.9 4154.59 1413.67 15114.5 2 assessment_3 ZERO_TWO_LEFT True False 245191 nan 278161 nan 1779.24 10329.2 104953 687123 279759 609347 992.791 287316 1.4422e+06 2 assessment_3 ZERO_TWO_RIGHT True False 39368.2 nan 60891.5 nan 677.412 2784.82 27385.5 148704 54561.2 97761.5 160.092 91954.7 332075"},{"location":"documentation/tutorials/beta/#results","title":"Results","text":"<p>We will now compare mean beta activity during and inbetween regions of patient movement. We need to format the dataframe one last time to calculate the mean power across all activities...</p> <pre><code># Average power across activities for each row\ndf_activity = dataframe.drop(\"BASELINE\", axis=1).mean(axis=1)\n# Create a plotting dataframe\ndf_plot = pd.concat([dataframe[\"BASELINE\"], df_activity], axis=1)\ndf_plot.columns = [\"Baseline\", \"Activity\"]\n</code></pre> <p>...and simply visualise the result:</p> <pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig, ax = plt.subplots(figsize=(7, 6))\n\n# Format the Axis\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.set_facecolor([0.95, 0.95, 0.97])\nax.set_axisbelow(True)\nax.grid(color=\"white\", lw=1.5)\n\n# Plot the data\nsns.lineplot(df_plot.T, ax=ax)\nleg = ax.axes.get_legend()\nleg.set_title(\"Subject ID\")\n\n# Scale axes and set limits\nax.set_yscale(\"log\")\nax.set_xlim(-0.1, 1.1)\n\n# Set axis labels\nax.set_xlabel(\"Motor state\", fontsize=14)\nax.set_ylabel(\"log Power\", fontsize=14)\nax.tick_params(labelsize=12, left=True)\n\nplt.tight_layout()\n</code></pre> <p>Output:</p> <p></p> <p>The analysis reveals a difference between the two motor states with the estiamted beta power being consistently lower within activity regions. Interestingly, the baseline neuronal activity can vary widely between subjects. </p>"},{"location":"home/demo/","title":"Getting Started","text":"<p>To demonstrate the functionality of BrainSight we have prepared a sample notebook that introduces all of the basic concepts and modules.</p> <p>Feel free to have a go at <code>Colab</code></p>"},{"location":"home/install/","title":"Install via <code>pip</code>","text":"<p>BrainSight can be installed like many other python packages by simply running:</p> <pre><code>$ pip install brainsight\n</code></pre> <p>And that's it! BrainSight should be ready for use.</p> <p>NOTE: BrainSight requires <code>python=3.10</code> or higher</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>brainsight<ul> <li>brainsight.modules<ul> <li>brainsight.modules.base_module</li> <li>brainsight.modules.defaults</li> <li>brainsight.modules.lfp</li> <li>brainsight.modules.periodogram</li> <li>brainsight.modules.spectrogram</li> <li>brainsight.modules.utils</li> </ul> </li> <li>brainsight.types<ul> <li>brainsight.types.dataset</li> <li>brainsight.types.signal</li> <li>brainsight.types.utils</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/brainsight/__init__/","title":"brainsight","text":"<p>BrainSight accommodates easy and intuitive analysis of local field potential (LFP) data captured by the Percept PC device and saved as part of a multimodal data exported through the Kelvin platform.</p> <p><code>brainsight.types</code> contain classes designed to simplify the handling of multimodal datasets and timestamp-synchronised signals.</p> <p><code>brainsight.modules</code> allow for processing and plotting of the data using the custom typing, ensuring that the analysis is straightforward and robust.</p> <p>The most common <code>modules</code> and <code>types</code> can be directly accessed from <code>brainsight</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import brainsight as brain\n&gt;&gt;&gt; dataset = brain.Dataset(\"path/to/dataset_file.json\")\n&gt;&gt;&gt; dataset\nDataset: \n- ACTIVITY\n- MDS_UPDRS\n- ACCELEROMETER\n- LFP\n- POSE\n- ASSESSMENT_INFO\n- VIDEO_METADATA\nAdditional LFP shift: 0[ms]\n</code></pre>"},{"location":"reference/brainsight/modules/__init__/","title":"brainsight.modules","text":"<p>Modules for analysis and plotting of the multimodal Dataset</p> <p>Currently available modules include:</p> <ul> <li><code>LFP</code></li> <li><code>Periodogram</code> </li> <li><code>Spectrogram</code></li> </ul>"},{"location":"reference/brainsight/modules/base_module/","title":"brainsight.modules.base_module","text":""},{"location":"reference/brainsight/modules/base_module/#brainsight.modules.base_module.BaseModule","title":"<code>BaseModule(dataset: Dataset, **kwargs)</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base class for modules interacting with <code>Dataset</code> instances.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset instance containing the LFP signals and other data modalities.</p> required"},{"location":"reference/brainsight/modules/base_module/#brainsight.modules.base_module.BaseModule.get_data","title":"<code>get_data(channel: str, roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]], **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Abstract method for the extraction of plotting data. Its interface needs to be implemented by the child class.</p>"},{"location":"reference/brainsight/modules/base_module/#brainsight.modules.base_module.BaseModule.plot","title":"<code>plot(roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]] = None, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Abstract method for plotting. Its interface needs to be implemented by the child class.</p>"},{"location":"reference/brainsight/modules/defaults/","title":"brainsight.modules.defaults","text":"<p>Contains some default parameters for the plotting modules.</p>"},{"location":"reference/brainsight/modules/defaults/#brainsight.modules.defaults.BRAINWAVE_BANDS","title":"<code>BRAINWAVE_BANDS = {'delta': (0.0, 4.0), 'theta': (4.0, 8.0), 'alpha': (8.0, 13.0), 'beta': (13.0, 32.0), 'gamma': (32.0, 120.0)}</code>  <code>module-attribute</code>","text":"<p>Default brainwave frequency bands. Used by the <code>Periodogram</code> module.</p>"},{"location":"reference/brainsight/modules/lfp/","title":"brainsight.modules.lfp","text":""},{"location":"reference/brainsight/modules/lfp/#brainsight.modules.lfp.LFP","title":"<code>LFP(dataset: Dataset, low_freq: Optional[float] = None, high_freq: Optional[float] = None, filter_kwargs: Optional[dict] = None, **kwargs)</code>","text":"<p>             Bases: <code>BaseModule</code></p> <p>LFP module allows for filtering and plotting of the LFP signals</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset instance containing the LFP signals and other data modalities.</p> required <code>low_freq</code> <code>float or None</code> <p>The lower pass-band edge, by default None</p> <code>None</code> <code>high_freq</code> <code>float or None</code> <p>The upper pass-band edge, by default None</p> <code>None</code> <code>filter_kwargs</code> <code>dict or None</code> <p>Additional parameters passed to the <code>mne.filter.filter_data</code> function, by default <code>None</code></p> <code>None</code> Notes <p>The filtering applied depends on the provided <code>low_freq</code> and <code>high_freq</code> according to the documentation of <code>mne.filter.filter_data</code>:</p> <p>Applies a zero-phase low-pass, high-pass, band-pass, or band-stop filter to the channels selected by picks. low_freq and high_freq are the frequencies below which and above which, respectively, to filter out of the data. Thus the uses are:     * <code>low_freq &lt; high_freq</code>: band-pass filter     * <code>low_freq &gt; high_freq</code>: band-stop filter     * <code>low_freq is not None and high_freq is None</code>: high-pass filter     * <code>low_freq is None and high_freq is not None</code>: low-pass filter</p> <p>For more details, see: MNE - filter_data</p> <p>Methods:</p> Name Description <code>get_data</code> <p>Filter the signal of the selected LFP channel within the specified ROI.</p> <code>plot</code> <p>Plot the LFP signals for all channels within the dataset.</p> <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <p>Additional parameters passed to the the parent <code>BaseModule</code> class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset(\"path/to/dataset_file.json\")\n&gt;&gt;&gt; lfp = LFP(dataset)\n&gt;&gt;&gt; lfp.plot()\n</code></pre>"},{"location":"reference/brainsight/modules/lfp/#brainsight.modules.lfp.LFP.get_data","title":"<code>get_data(channel: str, roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]], **kwargs) -&gt; np.ndarray</code>","text":"<p>Filter (if either low_freq or high_freq is specified) the LFP signal of the selected channel and cut it to the given ROI.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>Channel of the LFP for which to process the signal.</p> required <code>roi</code> <code>Tuple[int, int] or Tuple[str, str], or str, or None</code> <p>Region of interest for which to process the LFP signal. Can be specified as: - <code>Tuple[int, int]</code>; a tuple of timestamps [miliseconds], - <code>Tuple[str, str]</code>; a tuple of time strings in the \"HH:MM:SS\" format, - <code>str</code>; name of the detected activity class, - <code>None</code>; the entire signal ROI is used.</p> required <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <p>Additional parameters passed to the <code>mne.filter.filter_data</code> function.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Values of the (filtered) LFP signal for the selected channel.</p>"},{"location":"reference/brainsight/modules/lfp/#brainsight.modules.lfp.LFP.plot","title":"<code>plot(roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]] = None, show_activity: bool = True, show_accelerometer: bool = False, **kwargs) -&gt; plt.Figure</code>","text":"<p>Plot the (filtered) LFP signals for all channels within the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>roi</code> <code>Tuple[int, int] or Tuple[str, str], or str, or None</code> <p>Region of interest for which to plot the LFP signals. Can be specified as: - <code>Tuple[int, int]</code>; a tuple of timestamps [miliseconds], - <code>Tuple[str, str]</code>; a tuple of time strings in the \"HH:MM:SS\" format, - <code>str</code>; name of the detected activity class, - <code>None</code>; the entire signal ROI is used.</p> <code>None</code> <code>show_activity</code> <code>bool</code> <p>Whether to show activity regions found within the selected ROI, by default True.</p> <code>True</code> <code>show_accelerometer</code> <code>bool</code> <p>Whether to show the accelerometer signal, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Figure</code> <p>LFP signal figure.</p>"},{"location":"reference/brainsight/modules/periodogram/","title":"brainsight.modules.periodogram","text":""},{"location":"reference/brainsight/modules/periodogram/#brainsight.modules.periodogram.Periodogram","title":"<code>Periodogram(dataset: Dataset, frequency_band: Optional[Tuple[float, float]] = None, bandwidth: Optional[float] = None, adaptive: bool = False, brainwave_bands: Dict[str, Tuple[float, float]] = defaults.BRAINWAVE_BANDS, psd_kwargs: Optional[dict] = None, **kwargs)</code>","text":"<p>             Bases: <code>BaseModule</code></p> <p>Periodogram module allows for calculation and plotting of multitapered periodograms of the LFP signals</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset instance containing the LFP signals and other data modalities.</p> required <code>frequency_band</code> <code>Tuple[float, float] or None</code> <p>Interval of frequencies for which to compute the PSD. If <code>None</code>, the band is set to (0, Nyquist), by default <code>None</code>.</p> <code>None</code> <code>bandwidth</code> <code>float or None</code> <p>Frequency bandwidth of the multi-taper window function in Hz. For a given frequency, frequencies at \u00b1 bandwidth / 2 are smoothed together. If <code>None</code>, the value is set to <code>8 * (signal.samplig_rate / len(signal))</code>, by default <code>None</code></p> <code>None</code> <code>adaptive</code> <code>bool</code> <p>Use adaptive weights to combine the tapered spectra into PSD (might be slower), by default False.</p> <code>False</code> <code>brainwave_bands</code> <code>Dict[str, Tuple[float, float]]</code> <p>Dictionary of LFP frequency bands used for plotting. The specified bands and their corresponding power are highlighted. By default the bands are set to: <code>{\"delta\": (0.0, 4.0), \"theta\": (4.0, 8.0), \"alpha\": (8.0, 13.0), \"beta\": (13.0, 32.0), \"gamma\": (32.0, 120.0)}</code></p> <code>BRAINWAVE_BANDS</code> <code>psd_kwargs</code> <code>dict or None</code> <p>Additional parameters passed to the <code>mne.time_frequency.psd_array_multitaper</code> function, by default <code>None</code></p> <code>None</code> Notes <p>The periodogram calculation is performed using the <code>mne.time_frequency.psd_array_multitaper</code> function. For more information about the algorithm visit: MNE - psd_array_multitaper</p> <p>Methods:</p> Name Description <code>get_data</code> <p>Compute a multitaper PSD for the selected LFP channel within the specified ROI.</p> <code>plot</code> <p>Plot the periodogram for all LFP channels within the dataset.</p> <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <p>Additional parameters passed to the the parent <code>BaseModule</code> class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset(\"path/to/dataset_file.json\")\n&gt;&gt;&gt; periodogram = Periodogram(dataset)\n&gt;&gt;&gt; periodogram.plot()\n</code></pre>"},{"location":"reference/brainsight/modules/periodogram/#brainsight.modules.periodogram.Periodogram.get_data","title":"<code>get_data(channel: str, roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]], **kwargs) -&gt; Tuple[np.ndarray, np.ndarray]</code>","text":"<p>Compute a multitaper PSD for the selected LFP channel within the specified ROI.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>Channel of the LFP for which to calculate the PSD.</p> required <code>roi</code> <code>Tuple[int, int] or Tuple[str, str], or str, or None</code> <p>Region of interest for which to calculate the PSD. Can be specified as: - <code>Tuple[int, int]</code>; a tuple of timestamps [miliseconds], - <code>Tuple[str, str]</code>; a tuple of time strings in the \"HH:MM:SS\" format, - <code>str</code>; name of the detected activity class, - <code>None</code>; the entire signal ROI is used.</p> required <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <p>Additional parameters passed to the the <code>mne.time_frequency.psd_array_multitaper</code> function.</p> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Estimated power and corresponding frequencies arrays</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset(\"path/to/dataset_file.json\")\n&gt;&gt;&gt; dataset.LFP\nDataset:\n- ZERO_TWO_RIGHT\n- ZERO_TWO_LEFT\n&gt;&gt;&gt; dataset.ACTIVITY\nACTIVITY:\n- LEG_AGILITY_RIGHT\n- FINGER_TAPPING_LEFT\n- GAIT_TOWARDS_CAMERA\n- HAND_MOVEMENTS_RIGHT\n- ARISING_FROM_CHAIR\n- FINGER_TAPPING_RIGHT\n- GAIT_FROM_CAMERA\n- TOE_TAPPING_LEFT\n- TOE_TAPPING_RIGHT\n- POSTURAL_TREMOR_OF_HANDS_LEFT\n- LEG_AGILITY_LEFT\n- HAND_MOVEMENTS_LEFT\n&gt;&gt;&gt; periodogram = Periodogram(dataset, frequency_band=(5.0, 50.0))\n&gt;&gt;&gt; psds, freqs = periodogram.get_data(channel=\"ZERO_TWO_RIGHT\", roi=\"ARISING_FROM_CHAIR\")\n</code></pre>"},{"location":"reference/brainsight/modules/periodogram/#brainsight.modules.periodogram.Periodogram.plot","title":"<code>plot(roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]] = None, norm: str = 'density', **kwargs) -&gt; plt.Figure</code>","text":"<p>Plot the periodogram for all LFP channels within the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>roi</code> <code>Tuple[int, int] or Tuple[str, str], or str, or None</code> <p>Region of interest for which to plot the PSD. Can be specified as: - <code>Tuple[int, int]</code>; a tuple of timestamps [miliseconds], - <code>Tuple[str, str]</code>; a tuple of time strings in the \"HH:MM:SS\" format, - <code>str</code>; name of the detected activity class, - <code>None</code>; the entire signal ROI is used.</p> <code>None</code> <code>norm</code> <code>(density, power, dB)</code> <p>Mode of the plotting norm. If <code>\"density\"</code>, the plot is normalised per channel so that the area sums up to 1.0. If <code>\"power\"</code>, the raw power is drawn. If <code>\"dB\"</code>, the power gets converted to dB, by default <code>\"desnity\"</code>.</p> <code>\"density\"</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Periodogram figure.</p>"},{"location":"reference/brainsight/modules/spectrogram/","title":"brainsight.modules.spectrogram","text":""},{"location":"reference/brainsight/modules/spectrogram/#brainsight.modules.spectrogram.Spectrogram","title":"<code>Spectrogram(dataset: Dataset, window_sec: float = 10.0, frequency_step: float = 1.0, frequency_band: Optional[Tuple[float, float]] = None, tfr_kwargs: dict = None, **kwargs)</code>","text":"<p>             Bases: <code>BaseModule</code></p> <p>Spectrogram module allows for calculation and plotting of multitapered spectrograms of the LFP signals</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>Dataset</code> <p>Dataset instance containing the LFP signals and other data modalities.</p> required <code>window_sec</code> <code>float</code> <p>Sliding time window size [in seconds] with which to compute the spectrogram.</p> <code>10.0</code> <code>frequency_step</code> <code>float</code> <p>Parameter controlling the spectral resolution of the spectrogram. Specifies the step size between estimated frequencies, by default <code>1.0</code>.</p> <code>1.0</code> <code>frequency_band</code> <code>Tuple[float, float] or None</code> <p>Interval of frequencies for which to compute the Spectrogram. If <code>None</code>, the band is set to (<code>frequency_step</code>, Nyquist), by default <code>None</code>.</p> <code>None</code> <code>tfr_kwargs</code> <code>dict or None</code> <p>Additional parameters passed to the <code>mne.time_frequency.tfr_array_multitaper</code> function, by default <code>None</code></p> <code>None</code> Notes <p>The spectrogram calculation is performed using the <code>mne.time_frequency.tfr_array_multitaper</code> function. For more information about the algorithm visit: MNE - tfr_array_multitaper</p> <p>Methods:</p> Name Description <code>get_data</code> <p>Compute a multitaper spectrogram for the selected LFP channel within the specified ROI.</p> <code>plot</code> <p>Plot the spectrogram for all LFP channels within the dataset.</p> <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <p>Additional parameters passed to the the parent <code>BaseModule</code> class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset(\"path/to/dataset_file.json\")\n&gt;&gt;&gt; spectrogram = Spectrogram(dataset)\n&gt;&gt;&gt; spectrogram.plot()\n</code></pre>"},{"location":"reference/brainsight/modules/spectrogram/#brainsight.modules.spectrogram.Spectrogram.get_data","title":"<code>get_data(channel: str, roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]], **kwargs) -&gt; Tuple[np.ndarray, np.ndarray]</code>","text":"<p>Compute a multitaper spectrogram for the selected LFP channel within the specified ROI.</p> <p>Parameters:</p> Name Type Description Default <code>channel</code> <code>str</code> <p>Channel of the LFP for which to calculate the spectrogram.</p> required <code>roi</code> <code>Tuple[int, int] or Tuple[str, str], or str, or None</code> <p>Region of interest for which to calculate the spectrogram. Can be specified as: - <code>Tuple[int, int]</code>; a tuple of timestamps [miliseconds], - <code>Tuple[str, str]</code>; a tuple of time strings in the \"HH:MM:SS\" format, - <code>str</code>; name of the detected activity class, - <code>None</code>; the entire signal ROI is used.</p> required <p>Other Parameters:</p> Name Type Description <code>**kwargs</code> <p>Additional parameters passed to the the <code>mne.time_frequency.tpr_array_multitaper</code> function.</p> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Estimated spectrogram and corresponding frequencies arrays</p>"},{"location":"reference/brainsight/modules/spectrogram/#brainsight.modules.spectrogram.Spectrogram.plot","title":"<code>plot(roi: Optional[Union[Tuple[int, int], Tuple[str, str], str]] = None, show_activity: bool = True, **kwargs) -&gt; plt.Figure</code>","text":"<p>Plot the spectrogram for all LFP channels within the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>roi</code> <code>Tuple[int, int] or Tuple[str, str], or str, or None</code> <p>Region of interest for which to plot the spectrogram. Can be specified as: - <code>Tuple[int, int]</code>; a tuple of timestamps [miliseconds], - <code>Tuple[str, str]</code>; a tuple of time strings in the \"HH:MM:SS\" format, - <code>str</code>; name of the detected activity class, - <code>None</code>; the entire signal ROI is used.</p> <code>None</code> <code>show_activity</code> <code>bool</code> <p>Whether to show activity regions found within the selected ROI, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Spectrogram figure.</p>"},{"location":"reference/brainsight/modules/utils/","title":"brainsight.modules.utils","text":"<p>Contains utility functions for the plotting modules.</p>"},{"location":"reference/brainsight/modules/utils/#brainsight.modules.utils.ms_to_str","title":"<code>ms_to_str(ms: int) -&gt; str</code>","text":"<p>Convert miliseconds into a string timestamp.</p>"},{"location":"reference/brainsight/modules/utils/#brainsight.modules.utils.nanpow2db","title":"<code>nanpow2db(y: np.ndarray) -&gt; np.ndarray</code>","text":"<p>Convert Power array to dB.</p>"},{"location":"reference/brainsight/modules/utils/#brainsight.modules.utils.str_to_ms","title":"<code>str_to_ms(string: str) -&gt; int</code>","text":"<p>Convert a string timestamp into miliseconds.</p>"},{"location":"reference/brainsight/types/__init__/","title":"brainsight.types","text":"<p>Data types used to easily navigate the multimodal dataset.</p> <p>Main data types include:</p> <ul> <li><code>Dataset</code></li> <li><code>Signal</code></li> </ul>"},{"location":"reference/brainsight/types/dataset/","title":"brainsight.types.dataset","text":""},{"location":"reference/brainsight/types/dataset/#brainsight.types.dataset.Dataset","title":"<code>Dataset(file_or_dict: Union[str, dict], name: str = 'Dataset')</code>","text":"<p>             Bases: <code>_Dataset</code></p> <p>A class for convenient handling of the dataset obtained from the Kelvin platform. It unpacks and formats the json file, and integrates with <code>brainsight</code>'s plotting functionality. All levels of the dataset are easily accessible as attributes of the initialised Dataset instance.</p> <p>Parameters:</p> Name Type Description Default <code>file_or_dict</code> <code>Union[str, dict]</code> <p>File path to a json file of the dataset downloaded from Kelvin, or the already loaded dataset dictionary.</p> required <p>Attributes:</p> Name Type Description <code>lfp_shift</code> <code>int</code> <p>Additional time shift [in miliseconds] settable by the user to manually adjust the timestamps of the LFP signals.</p> <p>Other Parameters:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the dataset, by default \"Dataset\"</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset(\"path/to/dataset_file.json\")\n&gt;&gt;&gt; dataset\nDataset:\n- LFP\n- MDS_UPDRS\n- ACTIVITY\n- ACCELEROMETER\n- VIDEO_METADATA\n- ASSESSMENT_INFO\n- POSE\nAdditional LFP shift: 0[ms]\n&gt;&gt;&gt; dataset.LFP\nLFP:\n- ZERO_TWO_LEFT\n- ZERO_TWO_RIGHT\n&gt;&gt;&gt; dataset.LFP.ZERO_TWO_LEFT\nSignal(N: 113661, ROI: (0, 454600), SamplingRate: 250.0Hz)\n</code></pre>"},{"location":"reference/brainsight/types/dataset/#brainsight.types.dataset.Dataset.lfp_shift","title":"<code>lfp_shift: int</code>  <code>property</code> <code>writable</code>","text":"<p>Additional time shift of the LFP signals. Assign it an integer value [miliseconds] to shift all LFP Signals returned by the Dataset by that value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dataset = Dataset(\"path/to/dataset_file.json\")\n&gt;&gt;&gt; dataset\nDataset:\n- LFP\n- MDS_UPDRS\n- ACTIVITY\n- ACCELEROMETER\n- VIDEO_METADATA\n- ASSESSMENT_INFO\n- POSE\nAdditional LFP shift: 0[ms]\n&gt;&gt;&gt; dataset.LFP.ZERO_TWO_LEFT\nSignal(N: 113661, ROI: (0, 454600), SamplingRate: 250.0Hz)\n&gt;&gt;&gt; dataset.lfp_shift = 800\n&gt;&gt;&gt; dataset\nDataset:\n- LFP\n- MDS_UPDRS\n- ACTIVITY\n- ACCELEROMETER\n- VIDEO_METADATA\n- ASSESSMENT_INFO\n- POSE\nAdditional LFP shift: 800[ms]\n&gt;&gt;&gt; dataset.LFP.ZERO_TWO_LEFT\nSignal(N: 113661, ROI: (800, 455400), SamplingRate: 250.0Hz)\n</code></pre>"},{"location":"reference/brainsight/types/signal/","title":"brainsight.types.signal","text":""},{"location":"reference/brainsight/types/signal/#brainsight.types.signal.Signal","title":"<code>Signal(values: List[float], timestamps: List[float], sampling_rate: Optional[Union[float, int]] = None)</code>","text":"<p>A class for convenient handling of dataset's signals. Each signal object contains values and timestamps of the signal ensuring accurate calculations and plotting.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>List[float]</code> <p>List of signal values.</p> required <code>timestamps</code> <code>List[float]</code> <p>List of timestamps corresponding to the signal values.</p> required <code>sampling_rate</code> <code>float or int, or None</code> <p>Sampling rate of the signal [in Hz]. If <code>None</code>, the sampling rate will be inferred as from the median timestamp difference, by default <code>None</code>.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>values</code> <code>ndarray</code> <p>Numpy array containing signal values.</p> <code>timestamps</code> <code>ndarray</code> <p>Numpy array containing signal timestamps.</p> <code>ts</code> <code>ndarray</code> <p>Alias for <code>timestamps</code>.</p> <code>sampling_rate</code> <code>float</code> <p>Sampling rate of the signal.</p> <code>SamplingRate</code> <code>float</code> <p>Alias for <code>sampling_rate</code>.</p> <code>roi</code> <code>Tuple[int, int]</code> <p>Tuple indicating the first and last timestamp of the signal.</p> <code>ROI</code> <code>Tuple[int, int]</code> <p>Alias for <code>roi</code>.</p> <p>Methods:</p> Name Description <code>shift</code> <p>Temporally shifts the Signal's timestamps. Returns a new Signal instance.</p> <code>to_dict</code> <p>Converts the signal to a dictionary with serialisable typing.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p><code>values</code> and <code>timestamps</code> are of different length.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; signal = Signal(values=[0.2, 0.3, 0.1], timestamps=[1, 2, 3])\n&gt;&gt;&gt; signal\nSignal(N: 3, ROI: (1, 3), SamplingRate: 1000.0Hz)\n&gt;&gt;&gt; signal.values\narray([0.2, 0.3, 0.1])\n&gt;&gt;&gt; signal.timestamps\narray([1, 2, 3])\n&gt;&gt;&gt; signal.roi\n(1, 3)\n</code></pre>"},{"location":"reference/brainsight/types/signal/#brainsight.types.signal.Signal.shift","title":"<code>shift(shift_ms: int)</code>","text":"<p>Temporaly shifts the Signal by adding <code>shift_ms</code> to the Signal's timestamps. Returns a new Signal instance.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; signal = Signal(values=[0.2, 0.3, 0.1], timestamps=[1, 2, 3])\n&gt;&gt;&gt; signal\nSignal(N: 3, ROI: (1, 3), SamplingRate: 1000.0Hz)\n&gt;&gt;&gt; signal.shift(100)\nSignal(N: 3, ROI: (101, 103), SamplingRate: 1000.0Hz)\n&gt;&gt;&gt; signal.shift(-5)\nSignal(N: 3, ROI: (-4, -2), SamplingRate: 1000.0Hz)\n</code></pre>"},{"location":"reference/brainsight/types/signal/#brainsight.types.signal.Signal.to_dict","title":"<code>to_dict() -&gt; Dict[str, list]</code>","text":"<p>Converts the signal to a dictionary with serialisable typing.</p>"},{"location":"reference/brainsight/types/utils/","title":"brainsight.types.utils","text":""}]}